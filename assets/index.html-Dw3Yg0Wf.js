import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as n,c as t,b as i}from"./app-BPRPgYLJ.js";const r={},s=i(`<p>内核模块用于控制 <strong>nginx服务器</strong> 的基本功能，内核参数的修改需要重新启动nginx才能生效？？？</p><h3 id="用于调试进程-定位问题的配置项" tabindex="-1"><a class="header-anchor" href="#用于调试进程-定位问题的配置项"><span>用于调试进程，定位问题的配置项</span></a></h3><h4 id="daemon" tabindex="-1"><a class="header-anchor" href="#daemon"><span>daemon</span></a></h4><div class="hint-container info"><p class="hint-container-title">是否以 守护进程 方式启动nginx</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： daemon on|off;
默认： daemon on;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>守护进程（daemon）</strong> 是 <strong>脱离终端</strong> 并且在 <strong>后台运行</strong> 的进程。 它脱离终端是为了避免进程执行过程中的信息在任何终端上显示，这样一来，进程也不会被任何终端所产生的信息所打断。 <code>nginx毫无疑问是一个需要以守护进程方式运行的服务</code>，因此，<strong>默认</strong> 都是以这种方式运行的。 不过 nginx 还是提供了 <strong>关闭</strong> 守护进程的模式，之所以提供这种模式，是为了 <strong>方便跟踪调试nginx</strong>，毕竟用 <strong>gdb</strong><sup>Linux常用的程序调试器</sup> 调试进程时最烦琐的就是<code>如何继续跟进fork出的子进程</code>了。</p></div><h4 id="master-process" tabindex="-1"><a class="header-anchor" href="#master-process"><span>master_process</span></a></h4><div class="hint-container info"><p class="hint-container-title">是否以 master/worker 方式工作</p><ul><li>on时（默认），以 <strong>master/worker</strong> 进程运行</li><li>off时，以 <strong>master</strong> 进程运行</li></ul><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法：master_process on|off;
默认：master_process on;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>默认 nginx 是以 <strong>一个master进程</strong> 管理 <strong>多个 worker进程</strong> 的方式运行的，几乎所有的产品环境下，nginx都以这种方式工作。</p><p>与daemon配置相同，提供 <strong>master_process</strong> 配置也是为了 <strong>方便跟踪调试nginx</strong>。如果用 <strong>关闭</strong> 了 <strong>master_process</strong> 方式，就不会 fork 出 worker子进程 来处理请求，而是用 <strong>master进程</strong> 自身来处理请求。</p></div><h4 id="error-log" tabindex="-1"><a class="header-anchor" href="#error-log"><span>error_log</span></a></h4><div class="hint-container info"><p class="hint-container-title">日志文件配置</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： error_log /path/to/file level;
默认： error_log logs/error.log error;
关闭： error_log /dev/null;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>path/to/file</strong> 参数可以是一个具体的文件</p><ul><li>默认情况下是 <strong>logs/error.log</strong> 文件，最好将它放到一个磁盘空间足够大的位置</li><li>可以是 <strong>/dev/null</strong>，这样就不会输出任何日志了，这也是关闭 <strong>error日志</strong> 的 <strong>唯一手段</strong></li><li>可以是 <strong>stderr</strong>，这样日志会输出到 <strong>标准错误文件</strong></li></ul><p><strong>level</strong> 是日志的输出级别</p><ul><li>取值范围是 <code>debug</code>、<code>info</code>、<code>notice</code>、<code>warn</code>、<code>error</code>、<code>crit</code>、<code>alert</code>、<code>emerg</code>，从左至右级别依次增大</li><li>如果日志级别设定到 <strong>debug</strong>，必须在 configure 时加入 <strong>-–with-debug</strong> 配置项</li></ul></div><h4 id="debug-points" tabindex="-1"><a class="header-anchor" href="#debug-points"><span>debug_points</span></a></h4><div class="hint-container info"><p class="hint-container-title">是否处理几个特殊的调试点</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： debug_points [stop|abort]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>该指令用于 nginx 调试，可用来帮助用户调试nginx。<strong>debug_points</strong> 接收2个参数，分别为：<strong>stop</strong> 和 <strong>abort</strong>。</p><p>nginx 在一些关键的错误逻辑中（nginx 1.0.14版本中有8处）设置了调试点。如果设置为 <strong>stop</strong>，那么 nginx 的代码执行到这些调试点时，会发出 <strong>SIGSTOP</strong> 信号。如果设置为 <strong>abort</strong>，则会产生一个 <strong>coredump</strong> 文件，可以使用gdb来查看nginx当时的各种信息。</p></div><h4 id="debug-connection" tabindex="-1"><a class="header-anchor" href="#debug-connection"><span>debug_connection</span></a></h4><div class="hint-container info"><p class="hint-container-title">仅对指定的客户端输出debug级别的日志</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： debug_connection [IP|CIDR]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这个配置项实际上属于 <strong>事件类</strong> 配置，因此，它必须放在 <strong>events{...}</strong> 中才有效。它的值可以是 <strong>IP地址</strong> 或 <strong>CIDR地址</strong> ，例如：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>events {
  debug_connection 10.224.66.14;
  debug_connection 10.224.57.0/24;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这样，仅仅来自以上 <strong>IP地址</strong> 的请求才会输出 <strong>debug级别</strong> 的日志，其他请求仍然沿用 <strong>error_log</strong> 中配置的日志级别。<code>上面这个配置对修复Bug很有用，特别是定位高并发请求下才会发生的问题。</code></p><p>使用 <strong>debug_connection</strong> 前，需确保在执行 <strong>configure</strong> 时已经加入了 <strong>--with-debug</strong> 参数，否则不会生效。</p></div><h4 id="worker-rlimit-core" tabindex="-1"><a class="header-anchor" href="#worker-rlimit-core"><span>worker_rlimit_core</span></a></h4><div class="hint-container info"><p class="hint-container-title">限制 coredump 核心转储文件的大小</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_rlimit_core size
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>在Linux系统中，当进程 <strong>发生错误</strong> 或 <strong>收到信号</strong> 而终止时，系统会将进程执行时的内存内容（<strong>核心映像</strong>）写入一个文件（<strong>core文件</strong>），以作为调试之用，这就是所谓的 <strong>核心转储（core dumps）</strong>。</p><p>当Nginx进程出现一些 <strong>非法操作（如内存越界）</strong> 导致进程直接被操作系统强制结束时，会 <strong>生成核心转储core文件</strong>，可以从 core 文件获取当时的堆栈、寄存器等信息，从而帮助我们定位问题。</p><p>但这种core文件中的许多信息 <strong>不一定是用户需要的</strong>，如果不加以限制，那么可能一个core文件会达到几GB，这样随便 <strong>coredumps</strong> 几次就会把磁盘占满，引发严重问题。</p><p>通过 <strong>worker_rlimit_core</strong> 配置可以限制 <strong>core文件</strong> 的大小，从而有效帮助用户定位问题。</p></div><h4 id="working-directory" tabindex="-1"><a class="header-anchor" href="#working-directory"><span>working_directory</span></a></h4><div class="hint-container info"><p class="hint-container-title">指定 coredump 文件生成目录</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： working_directory path
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>worker进程的工作目录。这个配置项的唯一用途就是设置 <strong>coredump</strong> 文件所放置的目录。因此，需确保 worker进程 <strong>有权限</strong> 向 <strong>working_directory</strong> 指定的目录中写入文件。</p></div><h3 id="正常运行的必备配置" tabindex="-1"><a class="header-anchor" href="#正常运行的必备配置"><span>正常运行的必备配置</span></a></h3><h4 id="env" tabindex="-1"><a class="header-anchor" href="#env"><span>env</span></a></h4><div class="hint-container info"><p class="hint-container-title">定义环境变量</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： env VAR|VAR=VALUE
事例：env TESTPATH=/tmp/;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>这个配置项可以让用户直接设置 <strong>操作系统</strong> 上的 <strong>环境变量</strong></p></div><h4 id="include" tabindex="-1"><a class="header-anchor" href="#include"><span>include</span></a></h4><div class="hint-container info"><p class="hint-container-title">嵌入其他配置文件</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： include /path/to/file;
事例： include mime.types;
事例： include vhost/*.conf;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>include 配置项 可以将 <strong>其他配置文件</strong> 嵌入到当前的 <strong>nginx.conf</strong> 文件中， 它的参数 既可以是 <strong>绝对路径</strong>，也可以是 <strong>相对路径</strong>（相对于Nginx的配置目录，即nginx.conf所在的目录）。 参数的值可以是一个 <strong>明确的文件名</strong>，也可以是含有 <strong>通配符*的文件名</strong>，同时可以一次嵌入多个配置文件。</p></div><h4 id="pid" tabindex="-1"><a class="header-anchor" href="#pid"><span>pid</span></a></h4><div class="hint-container info"><p class="hint-container-title">指定nginx的pid文件</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： pid /path/to/pid_file
默认： pid logs/nginx.pid;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>保存 <strong>master进程ID</strong> 的 pid文件存放路径。</p><p>默认与 <strong>configure</strong> 执行时的参数 <strong>–pid-path</strong> 所指定的路径是相同的，也可以随时修改，但应确保 nginx <strong>有权限</strong>在相应的目标中<strong>创建pid文件</strong>，该文件直接影响 nginx 是否可以运行。</p></div><h4 id="user" tabindex="-1"><a class="header-anchor" href="#user"><span>user</span></a></h4><div class="hint-container info"><p class="hint-container-title">指定运行 worker进程 的用户和组</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： user username [groupname];
默认： user nobody nobody;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>user用于设置 <strong>master进程</strong> 启动后，fork出的 <strong>worker进程</strong> 运行在哪个用户和用户组下。当按照 <strong><code>user username;</code></strong> 设置时，<strong>用户组名</strong> 与 <strong>用户名</strong> 相同。</p><p>若用户在 configure 命令执行时使用了参数 <strong><code>–user=username</code></strong> 和 <strong><code>–group=groupname</code></strong> ，此时 nginx.conf 将使用参数中指定的 <strong>用户</strong> 和 <strong>用户组</strong>。</p></div><h4 id="worker-rlimit-nofile" tabindex="-1"><a class="header-anchor" href="#worker-rlimit-nofile"><span>worker_rlimit_nofile</span></a></h4><div class="hint-container info"><p class="hint-container-title">指定 nginx worker进程 可以打开的最大句柄描述符个数</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_rlimit_nofile limit;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></div><h4 id="worker-rlimit-sigpending" tabindex="-1"><a class="header-anchor" href="#worker-rlimit-sigpending"><span>worker_rlimit_sigpending</span></a></h4><div class="hint-container info"><p class="hint-container-title">指定每个用户能够发往worker的信号的数量</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_rlimit_sigpending limit;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>设置每个用户发往 nginx 的 <strong>信号队列的大小</strong>。也就是说，当某个用户的信号队列满了，这个用户再发送的信号量会被 <strong>丢掉</strong></p></div><h3 id="优化性能相关的配置" tabindex="-1"><a class="header-anchor" href="#优化性能相关的配置"><span>优化性能相关的配置</span></a></h3><h4 id="worker-processes" tabindex="-1"><a class="header-anchor" href="#worker-processes"><span>worker_processes</span></a></h4><div class="hint-container info"><p class="hint-container-title">worker线程的个数</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_processes number;
默认： worker_processes 1;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>在 master/worker 运行方式下，即 <strong><code>master_process on;</code></strong> ，定义 <strong>worker进程</strong> 的个数。</p><p>通常应该为物理CPU核心个数减1；</p><p>worker进程的数量会直接影响性能。</p><p>每个 worker进程 都是 <strong>单线程的进程</strong>，它们会调用各个模块以实现多种多样的功能。 如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。</p><p>例如，如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I/O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。</p><p>多worker进程可以充分利用多核系统架构，但若worker进程的数量多于CPU内核数，那么会增大进程间切换带来的消耗（Linux是抢占式内核）。一般情况下，用户要配置与CPU内核数相等的worker进程，并且使用下面的worker_cpu_affinity配置来绑定CPU内核。</p></div><h4 id="worker-cpu-affinity" tabindex="-1"><a class="header-anchor" href="#worker-cpu-affinity"><span>worker_cpu_affinity</span></a></h4><div class="hint-container info"><p class="hint-container-title">绑定Nginx worker进程到指定的CPU内核</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_cpu_affinity cpumask[cpumask…]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>为什么要绑定worker进程到指定的CPU内核呢？假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。反之，如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。</p><p>例如，如果有4颗CPU内核，就可以进行如下配置：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>worker_processes 4;
worker_cpu_affinity 1000 0100 0010 0001;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>将第1个进程绑定到CPU0/CPU2上,将第2个进程绑定到CPU1/CPU3上,这个对于超线程CPU合适</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>worker_processes 1
worker_cpu_affinity 0101 1010;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：worker_cpu_affinity配置仅对Linux操作系统有效。Linux操作系统使用sched_setaffinity()系统调用实现这个功能。</p></div><h4 id="ssl-engine" tabindex="-1"><a class="header-anchor" href="#ssl-engine"><span>ssl_engine</span></a></h4><div class="hint-container info"><p class="hint-container-title">SSL硬件加速</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： ssl_engine device;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>如果服务器上有SSL硬件加速设备，那么就可以进行配置以加快SSL协议的处理速度。用户可以使用OpenSSL提供的命令来查看是否有SSL硬件加速设备：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>openssl engine -t
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></div><h4 id="timer-resolution" tabindex="-1"><a class="header-anchor" href="#timer-resolution"><span>timer_resolution</span></a></h4><div class="hint-container info"><p class="hint-container-title">系统调用 gettimeofday 的执行频率</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： timer_resolution t;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>默认情况下，每次内核的事件调用（如epoll、select、poll、kqueue等）返回时，都会执行一次gettimeofday，实现用内核的时钟来更新Nginx中的缓存时钟。 在早期的Linux内核中，gettimeofday的执行代价不小，因为中间有一次内核态到用户态的内存复制。 当需要降低gettimeofday的调用频率时，可以使用timer_resolution配置。例如，“timer_resolution 100ms；”表示至少每100ms才调用一次gettimeofday。</p><p>但在目前的大多数内核中，如x86-64体系架构，gettimeofday只是一次vsyscall，仅仅对共享内存页中的数据做访问，并不是通常的系统调用，代价并不大，一般不必使用这个配置。 而且，如果希望日志文件中每行打印的时间更准确，也可以使用它。</p></div><h4 id="worker-priority" tabindex="-1"><a class="header-anchor" href="#worker-priority"><span>worker_priority</span></a></h4><div class="hint-container info"><p class="hint-container-title">Nginx worker进程优先级设置</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_priority nice;
默认： worker_priority 0;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>该配置项用于设置Nginx worker进程的nice优先级。</p><p>在Linux或其他类UNIX操作系统中，当许多进程都处于可执行状态时，将按照所有进程的优先级来决定本次内核选择哪一个进程执行。 进程所分配的CPU时间片大小也与进程优先级相关，优先级越高，进程分配到的时间片也就越大（例如，在默认配置下，最小的时间片只有5ms，最大的时间片则有800ms）。 这样，优先级高的进程会占有更多的系统资源。</p><p>优先级由静态优先级和内核根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。 nice值是进程的静态优先级，它的取值范围是–20~+19，–20是最高优先级，+19是最低优先级。 因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小。</p></div><h3 id="事件类配置项" tabindex="-1"><a class="header-anchor" href="#事件类配置项"><span>事件类配置项</span></a></h3><h4 id="worker-connections" tabindex="-1"><a class="header-anchor" href="#worker-connections"><span>worker_connections</span></a></h4><div class="hint-container info"><p class="hint-container-title">每个worker的最大连接数</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： worker_connections number;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>定义每个worker进程可以同时处理的最大连接数。</p></div><h4 id="accept-mutex" tabindex="-1"><a class="header-anchor" href="#accept-mutex"><span>accept_mutex</span></a></h4><div class="hint-container info"><p class="hint-container-title">是否打开accept锁</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： accept_mutex[on|off]
默认： accept_mutext on;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>accept_mutex是Nginx的负载均衡锁，本书会在第9章事件处理框架中详述Nginx是如何实现负载均衡的。 这里，读者仅需要知道accept_mutex这把锁可以让多个worker进程轮流地、序列化地与新的客户端建立TCP连接。 当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会， 以此实现所有worker进程之上处理的客户端请求数尽量接近。</p><p>accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。</p></div><h4 id="lock-file" tabindex="-1"><a class="header-anchor" href="#lock-file"><span>lock_file</span></a></h4><div class="hint-container info"><p class="hint-container-title">lock文件的路径</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： lock_file path/file;
默认： lock_file logs/nginx.lock;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>accept锁可能需要这个lock文件，如果accept锁关闭，lock_file配置完全不生效。 如果打开了accept锁，并且由于编译程序、操作系统架构等因素导致Nginx不支持原子锁， 这时才会用文件锁实现accept锁（14.8.1节将会介绍文件锁的用法），这样lock_file指定的lock文件才会生效。</p><p>注意 　在基于i386、AMD64、Sparc64、PPC64体系架构的操作系统上，若使用GCC、Intel C++、SunPro C++编译器来编译Nginx， 则可以肯定这时的Nginx是支持原子锁的，因为Nginx会利用CPU的特性并用汇编语言来实现它（可以参考14.3节x86架构下原子操作的实现）。 这时的lock_file配置是没有意义的。</p></div><h4 id="accept-mutex-delay" tabindex="-1"><a class="header-anchor" href="#accept-mutex-delay"><span>accept_mutex_delay</span></a></h4><div class="hint-container info"><p class="hint-container-title">使用accept锁后到真正建立连接之间的延迟时间</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： accept_mutex_delay Nms;
默认： accept_mutex_delay 500ms;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。 这个accept锁不是阻塞锁，如果取不到会立刻返回。 如果有一个worker进程试图取accept锁而没有取到，它至少要等accept_mutex_delay定义的时间间隔后才能再次试图取锁。</p></div><h4 id="multi-accept" tabindex="-1"><a class="header-anchor" href="#multi-accept"><span>multi_accept</span></a></h4><div class="hint-container info"><p class="hint-container-title">批量建立新连接</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： multi_accept[on|off];
默认： multi_accept off;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>当事件模型通知有新连接时，尽可能地对本次调度中客户端发起的所有TCP请求都建立连接。</p></div><h4 id="use" tabindex="-1"><a class="header-anchor" href="#use"><span>use</span></a></h4><div class="hint-container info"><p class="hint-container-title">选择事件模型</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>语法： use[kqueue|rtsig|epoll|/dev/poll|select|poll|eventport];
默认： Nginx会自动使用最适合的事件模型
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>对于Linux操作系统来说，可供选择的事件驱动模型有poll、select、epoll三种。epoll当然是性能最高的一种，在9.6节会解释epoll为什么可以处理大并发连接。</p></div>`,53),a=[s];function o(l,d){return n(),t("div",null,a)}const p=e(r,[["render",o],["__file","index.html.vue"]]),u=JSON.parse('{"path":"/Nginx/Core/","title":"nginx内核模块","lang":"zh-CN","frontmatter":{"title":"nginx内核模块","lang":"zh-CN","date":"2023-06-20T10:04:14.000Z","permalink":"/Nginx/Core/","icon":"nginx","category":["nginx"],"tag":["nginx"],"description":"内核模块用于控制 nginx服务器 的基本功能，内核参数的修改需要重新启动nginx才能生效？？？ 用于调试进程，定位问题的配置项 daemon 是否以 守护进程 方式启动nginx 守护进程（daemon） 是 脱离终端 并且在 后台运行 的进程。 它脱离终端是为了避免进程执行过程中的信息在任何终端上显示，这样一来，进程也不会被任何终端所产生的信息所...","head":[["meta",{"property":"og:url","content":"https://shaohui-jin.github.io/Nginx/Core/"}],["meta",{"property":"og:title","content":"nginx内核模块"}],["meta",{"property":"og:description","content":"内核模块用于控制 nginx服务器 的基本功能，内核参数的修改需要重新启动nginx才能生效？？？ 用于调试进程，定位问题的配置项 daemon 是否以 守护进程 方式启动nginx 守护进程（daemon） 是 脱离终端 并且在 后台运行 的进程。 它脱离终端是为了避免进程执行过程中的信息在任何终端上显示，这样一来，进程也不会被任何终端所产生的信息所..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-03-11T10:00:43.000Z"}],["meta",{"property":"article:author","content":"石怜安"}],["meta",{"property":"article:tag","content":"nginx"}],["meta",{"property":"article:published_time","content":"2023-06-20T10:04:14.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-11T10:00:43.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"nginx内核模块\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-06-20T10:04:14.000Z\\",\\"dateModified\\":\\"2024-03-11T10:00:43.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"石怜安\\",\\"url\\":\\"https://shaohui-jin.github.io\\"}]}"]]},"headers":[{"level":3,"title":"用于调试进程，定位问题的配置项","slug":"用于调试进程-定位问题的配置项","link":"#用于调试进程-定位问题的配置项","children":[{"level":4,"title":"daemon","slug":"daemon","link":"#daemon","children":[]},{"level":4,"title":"master_process","slug":"master-process","link":"#master-process","children":[]},{"level":4,"title":"error_log","slug":"error-log","link":"#error-log","children":[]},{"level":4,"title":"debug_points","slug":"debug-points","link":"#debug-points","children":[]},{"level":4,"title":"debug_connection","slug":"debug-connection","link":"#debug-connection","children":[]},{"level":4,"title":"worker_rlimit_core","slug":"worker-rlimit-core","link":"#worker-rlimit-core","children":[]},{"level":4,"title":"working_directory","slug":"working-directory","link":"#working-directory","children":[]}]},{"level":3,"title":"正常运行的必备配置","slug":"正常运行的必备配置","link":"#正常运行的必备配置","children":[{"level":4,"title":"env","slug":"env","link":"#env","children":[]},{"level":4,"title":"include","slug":"include","link":"#include","children":[]},{"level":4,"title":"pid","slug":"pid","link":"#pid","children":[]},{"level":4,"title":"user","slug":"user","link":"#user","children":[]},{"level":4,"title":"worker_rlimit_nofile","slug":"worker-rlimit-nofile","link":"#worker-rlimit-nofile","children":[]},{"level":4,"title":"worker_rlimit_sigpending","slug":"worker-rlimit-sigpending","link":"#worker-rlimit-sigpending","children":[]}]},{"level":3,"title":"优化性能相关的配置","slug":"优化性能相关的配置","link":"#优化性能相关的配置","children":[{"level":4,"title":"worker_processes","slug":"worker-processes","link":"#worker-processes","children":[]},{"level":4,"title":"worker_cpu_affinity","slug":"worker-cpu-affinity","link":"#worker-cpu-affinity","children":[]},{"level":4,"title":"ssl_engine","slug":"ssl-engine","link":"#ssl-engine","children":[]},{"level":4,"title":"timer_resolution","slug":"timer-resolution","link":"#timer-resolution","children":[]},{"level":4,"title":"worker_priority","slug":"worker-priority","link":"#worker-priority","children":[]}]},{"level":3,"title":"事件类配置项","slug":"事件类配置项","link":"#事件类配置项","children":[{"level":4,"title":"worker_connections","slug":"worker-connections","link":"#worker-connections","children":[]},{"level":4,"title":"accept_mutex","slug":"accept-mutex","link":"#accept-mutex","children":[]},{"level":4,"title":"lock_file","slug":"lock-file","link":"#lock-file","children":[]},{"level":4,"title":"accept_mutex_delay","slug":"accept-mutex-delay","link":"#accept-mutex-delay","children":[]},{"level":4,"title":"multi_accept","slug":"multi-accept","link":"#multi-accept","children":[]},{"level":4,"title":"use","slug":"use","link":"#use","children":[]}]}],"git":{"createdTime":1710151243000,"updatedTime":1710151243000,"contributors":[{"name":"shaohui_jin","email":"1051131737@qq.com","commits":1}]},"readingTime":{"minutes":11.98,"words":3595},"filePathRelative":"zh/Nginx/Core.md","localizedDate":"2023年6月20日","excerpt":"<p>内核模块用于控制 <strong>nginx服务器</strong> 的基本功能，内核参数的修改需要重新启动nginx才能生效？？？</p>\\n<h3>用于调试进程，定位问题的配置项</h3>\\n<h4>daemon</h4>\\n<div class=\\"hint-container info\\">\\n<p class=\\"hint-container-title\\">是否以 守护进程 方式启动nginx</p>\\n<div class=\\"language-text\\" data-ext=\\"text\\" data-title=\\"text\\"><pre class=\\"language-text\\"><code>语法： daemon on|off;\\n默认： daemon on;\\n</code></pre></div><p><strong>守护进程（daemon）</strong> 是 <strong>脱离终端</strong> 并且在 <strong>后台运行</strong> 的进程。\\n它脱离终端是为了避免进程执行过程中的信息在任何终端上显示，这样一来，进程也不会被任何终端所产生的信息所打断。\\n<code>nginx毫无疑问是一个需要以守护进程方式运行的服务</code>，因此，<strong>默认</strong> 都是以这种方式运行的。\\n不过 nginx 还是提供了 <strong>关闭</strong> 守护进程的模式，之所以提供这种模式，是为了 <strong>方便跟踪调试nginx</strong>，毕竟用 <strong>gdb</strong><sup>Linux常用的程序调试器</sup> 调试进程时最烦琐的就是<code>如何继续跟进fork出的子进程</code>了。</p>\\n</div>","autoDesc":true}');export{p as comp,u as data};
